{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import earthaccess\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import requests\n",
    "import tempfile\n",
    "import matplotlib.pyplot as plt\n",
    "import rioxarray as rxr\n",
    "import opera_utils\n",
    "import pandas as pd\n",
    "import os\n",
    "import psutil\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "\n",
    "ncpus = len(psutil.Process().cpu_affinity())    # number of available CPUs\n",
    "print('number of available CPUs: ', ncpus)\n",
    "ncpus = 10  # manually set nworkers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authenticate with NASA Earthdata Login\n",
    "auth = earthaccess.login(strategy=\"netrc\")\n",
    "req_session = auth.get_session()\n",
    "\n",
    "# Define the date range\n",
    "start_date = datetime(2016, 1, 1)\n",
    "end_date = datetime(2025, 5, 21)       # Sanity check\n",
    "\n",
    "threshold_snowcover = 40    # threshold of snow cover\n",
    "\n",
    "# Define the CMR-STAC API endpoint and collection ID\n",
    "stac_api_url = \"https://cmr.earthdata.nasa.gov/stac/NSIDC_ECS\"\n",
    "collection_id = \"C2015398723-NSIDC_ECS\"  # This is the collection ID for MOD10CM\n",
    "\n",
    "figure_dir = 'figures_snowcover'\n",
    "os.makedirs(figure_dir, exist_ok=True)\n",
    "\n",
    "output_geojson = 'blockout_snow_disp_s1.geojson'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_snow_cover_data_filter(year, month, gdf_frame, threshold_snowcover=40):\n",
    "    # Format the date string\n",
    "    date_str = f\"{year}-{month:02d}-01\"\n",
    "    end_date_str = (datetime(year, month, 1) + timedelta(days=32)).replace(day=1).strftime(\"%Y-%m-%d\")\n",
    "    \n",
    "    # Search for granules\n",
    "    results = earthaccess.search_data(\n",
    "        short_name=\"MOD10CM\",\n",
    "        cloud_hosted=True,\n",
    "        temporal=(date_str, end_date_str),\n",
    "        bounding_box=(-180, -90, 180, 90)  # Global coverage\n",
    "    )\n",
    "    \n",
    "    if results:\n",
    "        # Get the first granule (should only be one per month)\n",
    "        granule = results[0]\n",
    "        urls = granule.data_links()\n",
    "        \n",
    "        if urls:\n",
    "            url = urls[0]\n",
    "            print(f\"Streaming snow cover data for {year}-{month:02d}...\")\n",
    "\n",
    "            try:\n",
    "                # Stream the content to a temporary file\n",
    "                with tempfile.NamedTemporaryFile(delete=False, suffix='.hdf') as temp_file:\n",
    "                    print(f\"Downloading file from {url}\")\n",
    "                    with requests.get(url, stream=True) as response:\n",
    "                        response.raise_for_status()  # Raise an exception for bad status codes\n",
    "                        for chunk in response.iter_content(chunk_size=8192):\n",
    "                            temp_file.write(chunk)\n",
    "                    temp_file_path = temp_file.name\n",
    "                \n",
    "                print(f\"File downloaded successfully to temporary location: {temp_file_path}\")\n",
    "\n",
    "                fname=f\"HDF4_EOS:EOS_GRID:{temp_file_path}:MOD_CMG_Snow_5km:Snow_Cover_Monthly_CMG\"\n",
    "                dataset = rxr.open_rasterio(fname)\n",
    "                \n",
    "                snowcover = dataset.isel(band=0) # Select the first band and plot it\n",
    "                gdf_frame = gdf_frame.to_crs(snowcover.rio.crs)\n",
    "\n",
    "                # Clip the raster to the GeoDataFrame\n",
    "                clipped = snowcover.rio.clip(gdf_frame.geometry)\n",
    "                clipped = clipped.where(clipped <= 250, np.nan)\n",
    "\n",
    "                # Plot the clipped raster\n",
    "                plt.figure(figsize=(10, 6))\n",
    "                clipped.plot(cmap=\"viridis\", vmin=0, vmax=100)\n",
    "                plt.xlim(-180,-50)\n",
    "                plt.ylim(0,80)\n",
    "                plt.title(f\"Monthly Snow Cover {dataset.attrs['RANGEBEGINNINGDATE']} to {dataset.attrs['RANGEENDINGDATE']}\")\n",
    "                figname = f\"{figure_dir}/monthly_snow_cover_{dataset.attrs['RANGEBEGINNINGDATE']}_{dataset.attrs['RANGEENDINGDATE']}.png\"\n",
    "                plt.savefig(figname, dpi=300, bbox_inches='tight')\n",
    "                plt.close()\n",
    "\n",
    "                # Calculate mean snow cover for each frame_id\n",
    "                mean_values = []\n",
    "\n",
    "                # Suppress RuntimeWarnings temporarily\n",
    "                with warnings.catch_warnings():\n",
    "                    warnings.simplefilter(\"ignore\", category=RuntimeWarning)\n",
    "                    \n",
    "                    for idx, row in gdf_frame.iterrows():\n",
    "                        frame_id = row['frame_id']\n",
    "                        geometry = row['geometry']\n",
    "                                                \n",
    "                        # Clip the raster to the current geometry\n",
    "                        clipped = snowcover.rio.clip([geometry])\n",
    "                        \n",
    "                        # Remove pixels above 250\n",
    "                        clipped = clipped.where(clipped <= 100, np.nan)\n",
    "                        \n",
    "                        # Calculate the mean of the clipped raster \n",
    "                        mean_value = np.nanmean(clipped).item()  # .item() extracts the scalar from the array\n",
    "                        mean_values.append(mean_value)\n",
    "\n",
    "                        # Plot a clipped raster\n",
    "                        if frame_id==25018:\n",
    "                            plt.figure(figsize=(10, 6))\n",
    "                            clipped.plot(cmap=\"viridis\", vmin=0, vmax=100)\n",
    "                            plt.title(f\"Frame ID {frame_id} ({mean_value:.2f} % Snow Cover) \\n {dataset.attrs['RANGEBEGINNINGDATE']} to {dataset.attrs['RANGEENDINGDATE']}\")\n",
    "                            figname = f\"{figure_dir}/F{frame_id}_{dataset.attrs['RANGEBEGINNINGDATE']}_{dataset.attrs['RANGEENDINGDATE']}.png\"\n",
    "                            plt.savefig(figname, dpi=300, bbox_inches='tight')\n",
    "                            plt.close()\n",
    "\n",
    "                # Append mean_values as a column in gdf_frames\n",
    "                gdf_frame[\"mean_snowcover\"] = mean_values\n",
    "\n",
    "                # Replace nans to -1 so we can track later\n",
    "                if hasattr(gdf_frame['mean_snowcover'], 'fillna'):\n",
    "                    gdf_frame['mean_snowcover'] = gdf_frame['mean_snowcover'].fillna(-1)\n",
    "                else:\n",
    "                    gdf_frame['mean_snowcover'].fillna(-1, inplace=True)\n",
    "\n",
    "                gdf_frame['to_process'] = gdf_frame['mean_snowcover'].apply(lambda x: 0 if x >= threshold_snowcover else 1)\n",
    "\n",
    "                gdf_frame = gdf_frame.drop(['is_land', 'is_north_america', 'orbit_pass'], axis=1).reset_index(drop=True)\n",
    "                gdf_frame.insert(1, 'year', year)\n",
    "                gdf_frame.insert(2, 'month', month)\n",
    "\n",
    "                return gdf_frame\n",
    "\n",
    "            except requests.RequestException as e:\n",
    "                print(f\"Error downloading the file: {e}\")\n",
    "            except Exception as e:\n",
    "                print(f\"An error occurred: {e}\")\n",
    "            finally:\n",
    "                # Clean up the temporary file\n",
    "                if 'temp_file_path' in locals() and os.path.exists(temp_file_path):\n",
    "                    os.unlink(temp_file_path)\n",
    "                    # print(f\"Cleaned up: Temporary file removed.\")\n",
    "\n",
    "    else:\n",
    "        print(f\"No data found for {year}-{month:02d}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_month(year, month, gdf_frames, threshold_snowcover):\n",
    "    return get_snow_cover_data_filter(year, month, gdf_frames, threshold_snowcover)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_frames = opera_utils.get_frame_geojson(as_geodataframe=True)\n",
    "if gdf_frames.index.name == 'frame_id':     \n",
    "    gdf_frames = gdf_frames.reset_index()\n",
    "\n",
    "gdf_frames = gdf_frames.loc[gdf_frames.is_north_america.isin([1, '1'])].reset_index(drop=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a list of (year, month) tuples for the date range\n",
    "date_range = []\n",
    "current_date = start_date\n",
    "while current_date <= end_date:\n",
    "    date_range.append((current_date.year, current_date.month))\n",
    "    current_date += timedelta(days=32)\n",
    "    current_date = current_date.replace(day=1)\n",
    "\n",
    "# Process data for the entire date range in parallel with progress bar\n",
    "all_gdf_frames = []\n",
    "with ProcessPoolExecutor(max_workers=ncpus) as executor:\n",
    "    futures = [executor.submit(process_month, year, month, gdf_frames, threshold_snowcover) for year, month in date_range]\n",
    "    \n",
    "    for future in tqdm(as_completed(futures), total=len(futures), desc=\"Processing months\"):\n",
    "        result = future.result()\n",
    "        if result is not None:\n",
    "            all_gdf_frames.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_gdf = pd.concat(all_gdf_frames, ignore_index=True)\n",
    "merged_gdf = merged_gdf.sort_values(by=['year', 'month', 'frame_id']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the GeoDataFrame to a GeoJSON file\n",
    "merged_gdf.to_file(\"snowcover_database.geojson\", driver=\"GeoJSON\")\n",
    "merged_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add column that combies year and month in a datetime format\n",
    "merged_gdf['date'] = pd.to_datetime(merged_gdf[['year', 'month']].assign(day=1))\n",
    "merged_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list frame_id with snow cover above threshold from merged_gdf\n",
    "frameid_lst_snow = merged_gdf.loc[merged_gdf['mean_snowcover'] >= threshold_snowcover, 'frame_id'].unique()\n",
    "frameid_lst_snow = list(set(frameid_lst_snow))\n",
    "frameid_lst_snow = pd.DataFrame(frameid_lst_snow, columns=['frame_id'])\n",
    "frameid_lst_snow.to_csv('frameid_lst_snow.csv', index=False)\n",
    "frameid_lst_snow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(pd.to_datetime(merged_gdf.loc[(merged_gdf['frame_id']==25018) & (merged_gdf['mean_snowcover'] != -1)]['date']), merged_gdf.loc[(merged_gdf['frame_id']==25018) & (merged_gdf['mean_snowcover'] != -1)]['mean_snowcover'], marker='o', alpha=0.5, label='Fairbanks')\n",
    "plt.plot(pd.to_datetime(merged_gdf.loc[(merged_gdf['frame_id']==4839) & (merged_gdf['mean_snowcover'] != -1)]['date']), merged_gdf.loc[(merged_gdf['frame_id']==4839) & (merged_gdf['mean_snowcover'] != -1)]['mean_snowcover'],  marker='o',  alpha=0.5, label='Panama')\n",
    "plt.plot(pd.to_datetime(merged_gdf.loc[(merged_gdf['frame_id']==36545) & (merged_gdf['mean_snowcover'] != -1)]['date']), merged_gdf.loc[(merged_gdf['frame_id']==36545) & (merged_gdf['mean_snowcover'] != -1)]['mean_snowcover'],  marker='o', alpha=0.5, label='Sierra Nevada')\n",
    "plt.plot(pd.to_datetime(merged_gdf.loc[(merged_gdf['frame_id']==11114) & (merged_gdf['mean_snowcover'] != -1)]['date']), merged_gdf.loc[(merged_gdf['frame_id']==11114) & (merged_gdf['mean_snowcover'] != -1)]['mean_snowcover'],  marker='o', alpha=0.5, label='Central Valley+Sierra Nevada')\n",
    "plt.legend(loc='upper center', ncol=4)\n",
    "plt.xlabel('Date', fontsize=20)\n",
    "plt.ylabel('Mean Snow Cover (%)', fontsize=20)\n",
    "plt.ylim(-1, 111)\n",
    "plt.xlim(datetime(2019, 6, 1), datetime(2021, 8, 1))\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 6))\n",
    "merged_gdf.loc[merged_gdf['frame_id']==25018].groupby('month')['mean_snowcover'].apply(np.nanmean).replace(-1, np.nan).plot(label='Fairbanks', marker='o') \n",
    "merged_gdf.loc[merged_gdf['frame_id']==4839].groupby('month')['mean_snowcover'].apply(np.nanmean).replace(-1, np.nan).plot(label='Panama', marker='o') \n",
    "merged_gdf.loc[merged_gdf['frame_id']==36545].groupby('month')['mean_snowcover'].apply(np.nanmean).replace(-1, np.nan).plot(label='Sierra Nevada', marker='o') \n",
    "merged_gdf.loc[merged_gdf['frame_id']==11114].groupby('month')['mean_snowcover'].apply(np.nanmean).replace(-1, np.nan).plot(label='Central Valley + Sierra Nevada', marker='o') \n",
    "plt.legend(loc='upper center', ncol=4)\n",
    "plt.xlabel('Month', fontsize=20)\n",
    "plt.ylabel('Mean Snow Cover (%)', fontsize=20)\n",
    "plt.ylim(-1, 111)\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.xticks(range(1, 13), ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'], fontsize=14)\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frameid_lst_snow = []\n",
    "\n",
    "# Plot the results as a function of month  \n",
    "plt.figure(figsize=(15, 6))\n",
    "for frame_id in merged_gdf['frame_id'].unique():\n",
    "    mean_snowcover = merged_gdf.loc[merged_gdf['frame_id']==frame_id].groupby('month')['mean_snowcover'].apply(np.nanmean).replace(-1, np.nan)\n",
    "    std_snowcover = merged_gdf.loc[merged_gdf['frame_id']==frame_id].groupby('month')['mean_snowcover'].apply(np.nanstd).replace(-1, np.nan)\n",
    "    # plt.errorbar(mean_snowcover.index, mean_snowcover, yerr=std_snowcover, alpha=0.1, color='b')    \n",
    "    plt.plot(mean_snowcover.index, mean_snowcover, color='b',alpha=0.05)\n",
    "    # print(f\"Frame ID: {frame_id}, Mean Snow Cover: {mean_snowcover}\")\n",
    "    if mean_snowcover.max()>=threshold_snowcover:\n",
    "        frameid_lst_snow.append(frame_id)\n",
    "plt.xlabel('Month', fontsize=20)\n",
    "plt.ylabel('Mean Snow Cover (%)', fontsize=20)\n",
    "plt.xticks(range(1, 13), ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'], fontsize=14)\n",
    "plt.yticks(fontsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frameid_lst_snow = list(set(frameid_lst_snow))\n",
    "frameid_lst_snow = pd.DataFrame(frameid_lst_snow, columns=['frame_id'])\n",
    "frameid_lst_snow.to_csv('frameid_lst_snow.csv', index=False)\n",
    "frameid_lst_snow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean of the mean_snowcover per month over the years. \n",
    "plt.figure(figsize=(15, 6))\n",
    "for frame_id in merged_gdf['frame_id'].unique():\n",
    "    mean_snowcover = merged_gdf.loc[merged_gdf['frame_id']==frame_id].groupby('month')['mean_snowcover'].apply(np.nanmean).replace(-1, np.nan)\n",
    "    std_snowcover = merged_gdf.loc[merged_gdf['frame_id']==frame_id].groupby('month')['mean_snowcover'].apply(np.nanstd).replace(-1, np.nan)\n",
    "    # plt.errorbar(mean_snowcover.index, mean_snowcover, yerr=std_snowcover, alpha=0.1, color='b')    \n",
    "    plt.plot(mean_snowcover.index, mean_snowcover, color='b',alpha=0.05)\n",
    "plt.xlabel('Month', fontsize=20)\n",
    "plt.ylabel('Mean Snow Cover (%)', fontsize=20)\n",
    "plt.xticks(range(1, 13), ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'], fontsize=14)\n",
    "plt.yticks(fontsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "\n",
    "# New dataframe with the frame_id, mean_snowcover, and month\n",
    "mean_snowcover_month = merged_gdf.groupby(['frame_id', 'month'])['mean_snowcover'].apply(np.nanmean).reset_index()\n",
    "\n",
    "# Drop/Keep   \n",
    "mean_snowcover_month['to_process'] = mean_snowcover_month['mean_snowcover'].apply(lambda x: 1 if x <= threshold_snowcover else 0)\n",
    "\n",
    "# Add column geometry to mean_snowcover_month\n",
    "mean_snowcover_month = mean_snowcover_month.merge(gdf_frames[['frame_id', 'geometry']], on='frame_id', how='left')\n",
    "\n",
    "# Convert mean_snowcover_month to a geopandas dataframe\n",
    "gdf_mean_snowcover_month = gpd.GeoDataFrame(mean_snowcover_month, geometry=\"geometry\")\n",
    "gdf_mean_snowcover_month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Center coordinates of the US\n",
    "us_center = [37.0902, -95.7129]\n",
    "\n",
    "# Plot to_process\n",
    "gdf_mean_snowcover_month[gdf_mean_snowcover_month['month'] == 2][['frame_id', 'geometry', 'to_process']].explore(\n",
    "    \"to_process\", \n",
    "    vmin=0,\n",
    "    vmax=1,\n",
    "    location=us_center, \n",
    "    zoom_start=3,\n",
    "    cmap=\"RdBu\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "# Filter the GeoDataFrame for January (month == 1)\n",
    "gdf_january = gdf_mean_snowcover_month[gdf_mean_snowcover_month['month'] == 1]\n",
    "\n",
    "# Create a figure and axis with a proportional aspect ratio\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "\n",
    "# Plot the geometries using 'to_process' as the color value\n",
    "cax = gdf_january.plot(\n",
    "    column='to_process',\n",
    "    cmap='RdBu',  # Colormap\n",
    "    vmin=0,       # Minimum value for the color range\n",
    "    vmax=1,       # Maximum value for the color range\n",
    "    linewidth=0.8,\n",
    "    edgecolor='black',\n",
    "    legend=False,  # Disable default legend\n",
    "    ax=ax,\n",
    "    alpha=0.5\n",
    ")\n",
    "\n",
    "ax.set_xlim(-180, -50)\n",
    "ax.xaxis.set_tick_params(labelsize=14)\n",
    "ax.yaxis.set_tick_params(labelsize=14)\n",
    "\n",
    "# Set the title\n",
    "ax.set_title('Snow Cover in January ', fontsize=20)\n",
    "\n",
    "# Set aspect ratio to be equal for proper proportional display\n",
    "# ax.set_aspect('equal')\n",
    "\n",
    "# Create a colorbar below the plot\n",
    "divider = make_axes_locatable(ax)\n",
    "cax = divider.append_axes(\"bottom\", size=\"5%\", pad=0.5)\n",
    "\n",
    "# Add the colorbar with horizontal orientation\n",
    "sm = plt.cm.ScalarMappable(cmap='RdBu', norm=plt.Normalize(vmin=0, vmax=1))\n",
    "cbar = fig.colorbar(sm, cax=cax, orientation='horizontal')\n",
    "cbar.set_ticks([0, 1])\n",
    "cbar.ax.tick_params(labelsize=14)\n",
    "cbar.set_label('Drop: 0 / Keep: 1', fontsize=20)\n",
    "\n",
    "\n",
    "# Remove any extra whitespace\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import calendar\n",
    "\n",
    "# Define the list of months for iteration\n",
    "months = gdf_mean_snowcover_month['month'].unique()\n",
    "\n",
    "# Loop through each month and generate a plot\n",
    "for month in months:\n",
    "    # Filter the GeoDataFrame for the current month\n",
    "    gdf_current_month = gdf_mean_snowcover_month[gdf_mean_snowcover_month['month'] == month]\n",
    "\n",
    "    # Create a figure and axis with a proportional aspect ratio\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "\n",
    "    # Plot the geometries using 'to_process' as the color value\n",
    "    gdf_current_month.plot(\n",
    "        column='to_process',\n",
    "        cmap='RdBu',  # Colormap\n",
    "        vmin=0,       # Minimum value for the color range\n",
    "        vmax=1,       # Maximum value for the color range\n",
    "        linewidth=0.8,\n",
    "        edgecolor='black',\n",
    "        legend=False,  # Disable default legend\n",
    "        ax=ax,\n",
    "        alpha=0.5\n",
    "    )\n",
    "\n",
    "    # Set axis limits (adjust to your region of interest)\n",
    "    ax.set_xlim(-180, -50)\n",
    "\n",
    "    # Set the tick labels to be larger\n",
    "    ax.xaxis.set_tick_params(labelsize=14)\n",
    "    ax.yaxis.set_tick_params(labelsize=14)\n",
    "\n",
    "    # Get month name from month number\n",
    "    month_name = calendar.month_name[month]\n",
    "\n",
    "    # Set the title with the current month\n",
    "    ax.set_title(f'{month_name}', fontsize=20)\n",
    "\n",
    "    # Create a colorbar below the plot\n",
    "    divider = make_axes_locatable(ax)\n",
    "    cax = divider.append_axes(\"bottom\", size=\"5%\", pad=0.5)\n",
    "\n",
    "    # Add the colorbar with horizontal orientation\n",
    "    sm = plt.cm.ScalarMappable(cmap='RdBu', norm=plt.Normalize(vmin=0, vmax=1))\n",
    "    cbar = fig.colorbar(sm, cax=cax, orientation='horizontal')\n",
    "    cbar.set_ticks([0, 1])\n",
    "    cbar.ax.tick_params(labelsize=14)\n",
    "    cbar.set_label('Drop: 0 / Keep: 1', fontsize=20)\n",
    "\n",
    "    # Remove any extra whitespace\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save the figure as a PNG file, with the month number in the filename\n",
    "    plt.savefig(f'{figure_dir}/{month}_mean_meansnowcover.png', format='png')\n",
    "\n",
    "    # Close the plot to free memory after saving\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the mean snow cover for each frame_id, for the entire date range, in a single plot, using gradient color for the frame_id.\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(merged_gdf['date'], merged_gdf['mean_snowcover'], c=merged_gdf['frame_id'], cmap='viridis')\n",
    "plt.colorbar(label='Frame ID')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Mean Snow Cover (%)')\n",
    "plt.title('Mean Snow Cover for Each Frame ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#histogram of mean snow cover\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(merged_gdf['mean_snowcover'], bins=10, color='skyblue', edgecolor='black', linewidth=1.2)\n",
    "plt.xlabel('Mean Snow Cover (%)')\n",
    "plt.ylabel('Frequency')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Center coordinates of the US\n",
    "us_center = [37.0902, -95.7129]\n",
    "year_selected = 2016\n",
    "month_selected = 12\n",
    "\n",
    "# Plot to_process\n",
    "merged_gdf[(merged_gdf['year'] == year_selected) & (merged_gdf['month'] == month_selected)][['frame_id', 'geometry', 'to_process']].explore(\n",
    "    \"to_process\", \n",
    "    vmin=0,\n",
    "    vmax=1,\n",
    "    location=us_center, \n",
    "    zoom_start=3,\n",
    "    cmap=\"RdBu\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_selected = 2016\n",
    "month_selected = 12\n",
    "frameID_selected = 42779\n",
    "\n",
    "# Plot to_process\n",
    "merged_gdf[(merged_gdf['year'] == year_selected) & (merged_gdf['month'] == month_selected) & (merged_gdf['frame_id'] == frameID_selected)][['frame_id', 'geometry', 'to_process']].explore(\n",
    "    \"to_process\", \n",
    "    vmin=0,\n",
    "    vmax=1,\n",
    "    cmap=\"RdBu\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_selected = 2016\n",
    "month_selected = 12\n",
    "frameID_selected = 33065\n",
    "\n",
    "# Plot to_process\n",
    "merged_gdf[(merged_gdf['year'] == year_selected) & (merged_gdf['month'] == month_selected) & (merged_gdf['frame_id'] == frameID_selected)][['frame_id', 'geometry', 'to_process']].explore(\n",
    "    \"to_process\", \n",
    "    vmin=0,\n",
    "    vmax=1,\n",
    "    cmap=\"RdBu\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to geojson file\n",
    "merged_gdf.to_file(output_geojson, driver=\"GeoJSON\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "calval-DISP_dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
